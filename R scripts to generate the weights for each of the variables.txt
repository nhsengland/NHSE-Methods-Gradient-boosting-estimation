Developing the weights for each variables

# The main script
library("gbm")

# Set the random seed to get run-to-run consistency
set.seed(%Question.rand.seed%)

# Read and prepare the data
the.data <- read.Alteryx("#1")
all.names <- names(the.data)
the.target <- all.names[1]
the.preds <- all.names[2:ncol(the.data)]
if (length(the.preds) == 1)
	stop.Alteryx("Two or more predictor fields need to be selected.")
if ('%Question.use.weights%' == "True") {
	the.weight <- all.names[ncol(the.data)]
	the.preds <- all.names[2:(ncol(the.data) - 1)]
}
target.data <- eval(parse(text = paste("the.data$", the.target, sep = "")))
if (class(target.data) == "factor")
	target.levels <- levels(target.data)

# The formula string
formula.string <- paste(the.target, paste(the.preds, collapse = " + "), sep = " ~ ")

# Construct the command string
command.string <- paste("gbm(formula = ", formula.string, ", data = the.data, ", sep = "")
if (exists("the.weight")) {
	# Rescale the weights so that the minimum weight value is one"
	eval(parse(text = paste("the.data$", the.weight, " <- the.data$", the.weight, "/min(the.data$", the.weight, ")", sep = "")))
	command.string <- paste(command.string, "weights = the.data$", the.weight, ", ", sep = "")
}
# is the target variable numeric?
target_class_is_numeric <- class(target.data) %in% c("numeric","integer")
# The type of target / distribtuion of the loss function
if ('%Question.type.distribution%' == "False") {
	if (length(unique(target.data)) == 1)
		stop.Alteryx("The target field has only a single value")
	if (target_class_is_numeric) {
		if (any(as.integer(target.data) != target.data)) {
			the.dist <- "gaussian"
		} else {
			if (length(unique(target.data)) == 2) {
				the.dist <- "bernoulli"
			}
			if (length(unique(target.data)) > 2 && length(unique(target.data)) < 100 && length(unique(target.data))/length(target.data) <= 0.2) {
				the.dist <- "poisson"
			}
			if (length(unique(target.data)) >= 100 || length(unique(target.data))/length(target.data) > 0.2) {
				the.dist <- "gaussian"
			}
		}
	} else {
		the.dist <- "multinomial"
		if ('%Question.use.weights%' == "True") {
			if (length(unique(target.data)) > 2) {
				stop.Alteryx("At the current time, sampling weights cannot be used with a multinomial loss function distribution")
			} else {
				the.dist <- "bernoulli"
				new.target <- rep(0, nrow(the.data))
				the.levels <- levels(target.data)
				new.target[as.character(target.data) == the.levels[2]] <- 1
				eval(parse(text = paste("the.data$", the.target, " <- new.target", sep = "")))
			}
		}
	}
} else {
	if ('%Question.type.continuous%' == "True") {
		if ('%Question.dist.gaussian%' == "True")
			the.dist <- "gaussian"
		if ('%Question.dist.laplace%' == "True")
			the.dist <- "laplace"
		if ('%Question.dist.t%' == "True")
			the.dist <- paste('list(name = "tdist", df = ', %Question.t.df%, ')', sep = "")
	}
	if ('%Question.type.count%' == "True") {
		the.dist <- "poisson"
	}
	if ('%Question.type.binomial%' == "True") {
		if (class(target.data) == "factor") {
			new.target <- rep(0, nrow(the.data))
			the.levels <- levels(target.data)
			if (length(the.levels) != 2)
				stop.Alteryx("The target field is not binomial")
			new.target[as.character(target.data) == the.levels[2]] <- 1
			eval(parse(text = paste("the.data$", the.target, " <- new.target", sep = "")))
		}
		if ('%Question.dist.bernoulli%' == "True")
			the.dist <- "bernoulli"
		if ('%Question.dist.adaboost%' == "True")
			the.dist <- "adaboost"
#		if ('%Question.dist.huberized%' == "True")
#			the.dist <- "huberized"
	}
	if ('%Question.type.multinomial%' == "True") {
		the.dist <- "multinomial"
		if ('%Question.use.weights%' == "True") {
			AlteryxMessage("At the current time, sampling weights cannot be used with a multinomial loss function distribution", iType = 3, iPriority = 3)
			stop("")
		}
	}
	if ('%Question.type.survival%' == "True") {
		the.dist <- "poisson"
	}
}
command.string <- paste(command.string, 'distribution = "', the.dist, '", ', sep = "")
# The maximum number of trees in the model
command.string <- paste(command.string, "n.trees = ", %Question.n.trees%, ", ", sep = "")
# The method to determine the preferred number of trees in the model
if ('%Question.assess.cv%' == "True") {
	command.string <- paste(command.string, "cv.folds = ", %Question.num.folds%, ", n.cores = ", %Question.n.cores%, ", ", sep = "")
	assess.string <- 'gbm.perf(the.model, method = "cv")'
}
if ('%Question.assess.test%' == "True") {
	train.frac <- 0.01*%Question.train.fraction%
	command.string <- paste(command.string, "train.fraction = ", train.frac, ", ", sep = "")
	assess.string <- 'gbm.perf(the.model, method = "test")'
}
if ('%Question.assess.oob%' == "True")
	assess.string <- 'gbm.perf(the.model, method = "OOB")'
# Add the remaining parameters to the command string
bag.frac <- 0.01*%Question.bag.fraction%
command.string <- paste(command.string, "bag.fraction = ", bag.frac, ", shrinkage = ", %Question.shrinkage%, ", interaction.depth = ", %Question.interaction.depth%, ", n.minobsinnode = ", %Question.n.minobsinnode%, ", keep.data = FALSE)", sep = "")

# Create the model and determine the "best" number of trees to use
the.model <- eval(parse(text = command.string))
the.model$best.trees <- eval(parse(text = assess.string))

# If the target is a factor, then place the factor levels into the object
if (exists("target.levels"))
	the.model$target.levels <- target.levels
# If the target is binary, calculate the percentage of the sample that go to each value
if (length(unique(target.data)) == 2) {
	the.values <- unique(target.data)[order(unique(target.data))]
	pct1 <- 100*length(target.data[target.data == the.values[1]])/length(target.data)
	the.model$sample.pct <- c(pct1, 100 - pct1)
}

# Create a list with the model object and its name and write it out via
# the third output
model.name <- validName('%Question.model.name%')
the.obj <- vector(mode="list", length=2)
the.obj[[1]] <- c(model.name)
the.obj[[2]] <- list(the.model)
names(the.obj) <- c("Name", "Object")
write.Alteryx(the.obj, nOutput = 3)

# Create the grp/out table
Distribution <- "Gaussian"
if (the.dist[1] == "laplace")
	Distribution <- "Laplace"
if (the.dist[1] == "tdist")
	Distribution <- "Student's t"
if (the.dist[1] == "poisson")
	Distribution <- "Poisson"
if (the.dist[1] == "bernoulli")
	Distribution <- "Bernoulli"
if (the.dist[1] == "adaboost")
	Distribution <- "AdaBoost"
#if (the.dist[1] == "huberized")
#	Distribution <- "Huberized"
if (the.dist[1] == "multinomial")
	Distribution <- "Multinomial"
if (Distribution == "Multinomial" && length(unique(target.data)) == 2)
	Distribution <- "Bernoulli"
Method <- "out-of-bag (which is biased toward too few trees)"
if ('%Question.assess.cv%' == "True")
	Method <- paste(%Question.num.folds%,"-fold cross validation", sep = "")
if ('%Question.assess.test%' == "True")
	Method <- paste("a test sample using ", (100 - %Question.train.fraction%), "% of the total sample for comparison", sep = "")
Warning <- ""
if (the.model$best.trees == the.model$n.trees) {
	Warning <- "Warning: The minimum of the loss function was likely not obtained. Consider re-running with a larger value for the maximum number of trees in the model." 
	AlteryxMessage("The minimum of the loss function was likely not obtained.", iType = 2, iPriority = 3)
}
out <- c(model.name, Distribution, the.model$n.trees, the.model$best.trees, Method, Warning)
grp <- c("Model_Name", "Distribution", "N_Trees", "Best_Trees", "Method", "Warning")
write.Alteryx(data.frame(grp = grp, out=out))

# Prepare the variable relative importance data from the model summary for plotting
model.summary <- summary(the.model, n.trees = the.model$best.trees, plotit = FALSE, order = FALSE)
model.summary$Index <- 1:nrow(model.summary)
new.summary <- model.summary[order(model.summary$rel.inf),]
new.summary$var <- as.character(new.summary$var)
new.summary$Index <- NULL
new.summary <- new.summary[new.summary$rel.inf > 0,]

# Create the plots
legend.loc <- "bottomleft"
if (the.model$best.trees < 0.5*the.model$n.trees)
	legend.loc <- "topright"
whr <- graphWHR(inches = '%Question.inches%', in.w = '%Question.in.w%', in.h = '%Question.in.h%', cm.w = '%Question.cm.w%', cm.h = '%Question.cm.h%', resolution = '%Question.graph.resolution%', print.high = FALSE)
AlteryxGraph(2, width = whr[1], height = whr[2], res = whr[3], pointsize = %Question.pointsize%)

dotchart(new.summary$rel.inf, labels = new.summary$var, xlab="Relative Importance", ylab = "", main = "Variable Importance Plot")
eval(parse(text = assess.string))
if ('%Question.assess.cv%' == "True")
	legend(x = legend.loc, legend=c("In Sample", "Cross Validation"), lwd = 1, col = c("black", "green"))
if ('%Question.assess.test%' == "True")
	legend(x = legend.loc, legend=c("In Sample", "Test Sample"), lwd = 1, col = c("black", "red"))
title(main = "Number of Iterations Assessment Plot", cex.main = 1.3)
if('%Question.marginal.plots%' == "True") {
	to.plot <- model.summary[model.summary$rel.inf > %Question.plot.min.importance%, ]
	to.plot <- to.plot[order(to.plot$rel.inf, decreasing = TRUE),]
	the.type <- "link"
	if (the.dist == "multinomial" || the.dist == "bernoulli" || the.dist == "poisson")
		the.type <- "response"
	for (i in to.plot$Index) {
		gbmPlot(the.model, i, the.model$best.trees, type = the.type)
		title(main = paste("Marginal Effect Plot of", as.character(to.plot$var[to.plot$Index == i])), cex.main = 1.3)
	}
}

invisible(dev.off())